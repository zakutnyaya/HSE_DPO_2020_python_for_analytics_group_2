{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Pyspark.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q21pS9Sf2ZD",
        "colab_type": "text"
      },
      "source": [
        "# Python для анализа данных\n",
        "\n",
        "# Spark / PySpark \n",
        "\n",
        "#### автор: Валентин Бирюков\n",
        "\n",
        "\n",
        "Spark является все более популярной кластерной вычислительной системой на основе Apache Hadoop, которая предлагает большую потенциальную ценность благодаря своей скорости и простоте использования. Мы рассмотрим его здесь, уделив особое внимание интерфейсу Python для Spark: PySpark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8jmWpOeENAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spark использует mapreduce техноологию\n",
        "# мы будем общаться с spark через локальный API с использованием SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WatFxPJmf2ZG",
        "colab_type": "text"
      },
      "source": [
        "Подготовка\n",
        "-------------\n",
        "\n",
        "Для работы нам потребуется собствено сам Spark который можно скачать и установить с официального сайта http://spark.apache.org/downloads.html\n",
        "\n",
        "Так же для его успешного функционирования потребуется Java8/11. И вот тут могут возникнуть сложности, поскольку сейчас последняя и поддерживаемая верся - Java11, но самостоятельная настройка может вызывать затруднение при совместимости пакетов, такие как ошибка вида:\n",
        "\n",
        "`Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe. : java.lang.IllegalArgumentException: Unsupported class file major version 55` \n",
        "\n",
        "в таком случае самый простой вариант запустить данный блокнот используя **Google Colab**. \n",
        "\n",
        "\n",
        "\n",
        "*Замечание 1:\n",
        "При локальном запуске и запуске в virtualenv мы должны указать Spark использовать текущую версию Python, иначе она будет использовать системную версию Python по умолчанию. Вставьте это в свой код: `os.environ['PYSPARK_PYTHON'] = sys.executable`.*\n",
        "\n",
        "*Замечание 2:\n",
        "Spark имеет веб-интерфейс, который показывает запущенные задачи, выполняющиеся процессы и различную статистику. Запуская локально, это может наблюдать в интерфесе http://localhost:4040/.*\n",
        "\n",
        "*Замечание 3:\n",
        "Запуская же ноутбук в **colab** чтобы получить такую ссылку раскомментируйте ячейку ниже и запустите ее. По этой ссылке будет доступен аналог локального хоста только для облачного блокнота. По этой ссылке доступ будет только у вас, залогиненных в учетной записи google. Для других же пользователей эта ссылка будет выдавать 403 ошибку - ошибку доступа к ресурсу.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0cvhwlXf2ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad1c9057-3aea-48f1-f93d-e5e48696cacc"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(4040)\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://o2gqkot9pq-496ff2e9c6d22116-4040-colab.googleusercontent.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tFSW3jf2ZM",
        "colab_type": "text"
      },
      "source": [
        "## Поставим сам модуль"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f68nbcYf2ZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "25e8ff16-f372-4fe7-c6e7-54ae8476ae2b"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 66kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 26.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=8066561adcc49e9a690831a4e60f2d7782cd30baf6e7cfce181cd07224f5013c\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5udxZpKhf2ZQ",
        "colab_type": "text"
      },
      "source": [
        "Обращения к pyspark\n",
        "---------------\n",
        "\n",
        "Чтобы вызвать Spark из Python, нам нужно использовать интерфейс PySpark. Например, его можно вызвать интерактивной оболочкой из вашей домашней директории Spark.:\n",
        "\n",
        "    ./bin/pyspark\n",
        "\n",
        "Как оболочка iPython Spark:\n",
        "\n",
        "    IPYTHON=1 ./bin/pyspark\n",
        "\n",
        "Или как пусковая установка для скриптов:\n",
        "\n",
        "    ./bin/pyspark --master local\n",
        "\n",
        "Ниже мы рассмотрим, как использовать API PySpark внутри скриптов Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyo_Vk4Vf2ZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Spark's home directory (here it's: ~/spark-1.6.0) should be set as an environment variable.\n",
        "# (Of course setting an env. variable doesn't need to be done from Python; any method will do.)\n",
        "# os.environ['SPARK_HOME'] = os.path.join(os.path.expanduser('~'), 'spark-1.6.0')\n",
        "\n",
        "# Add Spark's Python interface (PySpark) to PYTHONPATH.\n",
        "# (Again: this doesn't need to be done from Python.)\n",
        "# sys.path.append(os.path.join(os.environ.get('SPARK_HOME'), 'python'))\n",
        "\n",
        "# This can be useful for running in virtualenvs:\n",
        "# os.environ['PYSPARK_PYTHON'] = '/home/nico/virtualenv/bin/python'\n",
        "\n",
        "# OK, now we can import PySpark\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYlJrM9Wf2ZT",
        "colab_type": "text"
      },
      "source": [
        "Внутри нашей *рабочей программки* соединение с Spark представлено экземпляром `SparkContext`. Для локального запуска Spark вы можете просто создать его с помощью:\n",
        "\n",
        "    sc = SparkContext('local', 'mySparkApp')\n",
        "\n",
        "Кроме того, вы можете использовать экземпляр `SparkConf` для управления различными свойствами конфигурации Spark, что мы и будем рассматривать ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO7vBGwWf2ZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a8a56a9-1d6a-4c5c-96c9-32ab2e1e503c"
      },
      "source": [
        "# создаем пустой config\n",
        "conf = SparkConf()\n",
        "conf.toDebugString()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBY523Q8f2ZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52df2cbf-6985-4a05-fe3c-2a3a15fcdffb"
      },
      "source": [
        "# укажем что будем мы запускать все это локально\n",
        "conf.setMaster('local') # задаем машину, которая раздает задания другим машинам\n",
        "conf.setAppName('spark_tutorial') # некоторый alias нашего \"приложения\"\n",
        "# SparkConf имеет методы 'set', 'setAll' и 'setIfMissing' которые могут быть использованы\n",
        "# для уточнения конфигурации нашего \"кластера\" - той части которую мы хотим заиспользовать\n",
        "# например - задействовать 4 ядра и 1Gb оперативы\n",
        "conf.setIfMissing(\"spark.cores.max\", \"4\")\n",
        "conf.set(\"spark.executor.memory\", \"1g\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.conf.SparkConf at 0x7fed4adf47f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXf_JJsf2Za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4a067a8-34dc-460c-ab76-3a77b79418a1"
      },
      "source": [
        "# Другой вариан, задать все это разом:\n",
        "conf.setAll([('spark.cores.max', '4'), ((\"spark.executor.memory\", \"1g\"))])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.conf.SparkConf at 0x7fed4adf47f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avcO0jkNf2Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# И теперь запустим spark с такой конфигурацией\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# остановить же это можно с помощью следующей команды в ручном режиме:\n",
        "# sc.stop()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFEK0Jz5f2Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTpUHNTBf2Zj",
        "colab_type": "text"
      },
      "source": [
        "Как работает Spark, очень-очень вкратце\n",
        "-------------------------\n",
        "\n",
        "Spark использует *диспетчер кластеров* (например, собственный автономный менеджер Spark, YARN или Mesos) и несколько *рабочих узлов*. Менеджер задач (ака master/main) пытается получить *исполнителей* (ака slaves/secondary) на рабочих узлах, которые выполняют вычисления и хранят данные на основе кода и задач, которые им отправляются.\n",
        "\n",
        "\n",
        "Основная абстракция Spark - это так называемый *Resilient Distributed Dataset (RDD)*. Spark может создавать RDD из любого источника хранения, поддерживаемого Hadoop. RDD содержит промежуточные результаты вычислений и хранится в ОЗУ или на диске на рабочих узлах. В случае сбоя узла, RDD может быть восстановлен. Многие процессы могут выполняться параллельно благодаря распределенной природе RDD, а конвейерная обработка и отложенное выполнение предотвращают необходимость сохранения промежуточных результатов для следующего шага. Важно отметить, что Spark поддерживает извлечение наборов данных в кластерный *кэш в памяти* для быстрого доступа.\n",
        "\n",
        "Операции RDD можно разделить на 2 группы: *преобразования* (transform) и *действия* (actions). Преобразования (например, `map`) RDD всегда приводят к новым RDD, а действия (например, `reduce`) возвращают значения, которые являются результатом операций над RDD, обратно в программу драйвера.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Спарк - это надстройка, чтобы орекстировать кластерами - распределять задачи между машинами. Главный процесс раздает задания побочным, побочные выполняют задания, мастер затем все это собирает в один результат. rdd - распределенное хранилище данных. Промежуточные вычисления идут в память машины или на жесткий диск. Если одна из машин выходит из строя, мы можем восстанавливать данных, так как спарк использует механизм репликации. Реплика в оснвном создается на другом компьютере, который не используется для обработки, только для хранения реплики. \n",
        "К данным на жестком диске обращаться долго, к кешам - быстро, к оперативной памяти - быстрее, чем к жесткому диску, но медленнее, чем к кешу.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bs8TTMaf2Zj",
        "colab_type": "text"
      },
      "source": [
        "### RDD и распределенные данные\n",
        "\n",
        "Сейчас, когда мы запускаем все это дело локально на одной машине - они в реалиях не очень то распределенные, они лежат на физическом одном диске. Однако даже в этом случае запускаясь локально Spark будет оркестрировать всем, как будто у него маленький кластер. Настолько маленький, что ровно из одного вашего компьютера =)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkHiKA8Gf2Zk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f2b6a74-bced-470a-ac64-69c80c5f5c00"
      },
      "source": [
        "# 'parallelize' создает RDD путем распределения данных по кластеру\n",
        "rdd = sc.parallelize(range(14), numSlices=4)\n",
        "# по сути создаем список из 14 элементов которой храним распределенно, на 4 \"файлах\"\n",
        "print(\"Number of partitions: {}\".format(rdd.getNumPartitions()))\n",
        "# 'glom' перечисляет все элементы в каждом разделе\n",
        "# collect - это тот самый action\n",
        "print(rdd.glom().collect())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of partitions: 4\n",
            "[[0, 1, 2], [3, 4, 5, 6], [7, 8, 9], [10, 11, 12, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrSIxaoCf2Zm",
        "colab_type": "text"
      },
      "source": [
        "### Spark - ленивый\n",
        "Несмотря на любые промежуточные преобразования, Spark запускается только после выполнения *действия* на RDD. Это связано с тем, что он пытается выполнить умную конвейеризацию операций, чтобы не сохранять промежуточные результаты.\n",
        "\n",
        "Этакий знакомый аналог `map` в питоне, который по факту еще ничего не применяет\n",
        "\n",
        "только когда пишем collect массив разворачивается в памяти и происходит преобразование. только тогда получаем массив."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQd-cOesf2Zn",
        "colab_type": "code",
        "colab": {},
        "outputId": "81c79d98-0eb3-4ee6-a295-154488a6337b"
      },
      "source": [
        "rddSquared = rdd.map(lambda x: x ** 2)\n",
        "\n",
        "print(rddSquared.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeHrUvUSf2Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Альтернативный вариант, с созданием функции:\n",
        "def squared(x):\n",
        "    return x ** 2\n",
        "rddSquared = rdd.map(squared)\n",
        "print(rddSquared.collect())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVjCy0gqf2Zs",
        "colab_type": "text"
      },
      "source": [
        "В данных обоих случаях только `collect` инициировал работу с данными, остальные же созданные преобразования откладывались как \"состояния\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBfW9tPf2Zs",
        "colab_type": "text"
      },
      "source": [
        "Рассмотрим другие популярные преобразования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh3D3umSf2Zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d5f5936-c0c4-4944-cfa2-85d92af811e8"
      },
      "source": [
        "# Преобразования\n",
        "# flatMap - если обрабатываем массив массивов, то получим один распакованный список\n",
        "# -----------------------\n",
        "\n",
        "func = lambda x: -x\n",
        "rdd.map(func)\n",
        "rdd.flatMap(func) # почти как map, только результат будет распакован\n",
        "rdd.filter(func)\n",
        "rdd.sortBy(func)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[10] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGkQV2fzJOkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c13a4169-09b2-43db-d342-021857da1231"
      },
      "source": [
        "# не может сделать flatMap от функции\n",
        "rdd.flatMap(func).collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-29b40381c17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 16, 6da6b741fc15, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2133)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.6/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nTypeError: 'int' object is not iterable\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2133)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuFRyMJTJhQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a140b784-ae77-4b7c-e7f0-d763878732c3"
      },
      "source": [
        "# развернули и сделали преобразование\n",
        "import numpy as np\n",
        "sc.parallelize(np.array([[1,2], [3,4]]), numSlices=4).flatMap(lambda x: x**2).collect()\n",
        "# фильтрация\n",
        "sc.parallelize(range(15), numSlices=4).filter(lambda x: x%2).collect()\n",
        "# сортировка\n",
        "sc.parallelize(range(15), numSlices=4).sortBy(lambda x: -x).collect()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPr8WwlTf2Zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# действия\n",
        "# ---------------\n",
        "# reduce получает на вход пару объектов\n",
        "rdd.reduce(lambda x, y: x + y)\n",
        "rdd.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmhyZeZtK23C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0b5ee60-58c8-4996-eb72-4202e78ba0bc"
      },
      "source": [
        "print(sum(range(14))) # накопленная сумма\n",
        "rdd.reduce(lambda x, y: x + y) # reduce бежит окном, считаем накопленным итогом"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITnqyzEf2Zx",
        "colab_type": "text"
      },
      "source": [
        "В обоих этих случаях операции по сути никуда не применились, можно сказать что мы выстроили процесс по которому будут выполняться узлы, однако каждый из них вел в \"никуда\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCKWqZx7f2Zy",
        "colab_type": "code",
        "colab": {},
        "outputId": "7a4bf7d7-c79f-43c3-b986-3ce6821d8ff0"
      },
      "source": [
        "# Действия, возвращающие полученные в данные\n",
        "# в качестве действия можно использовать обращение к данным:\n",
        "print(rdd.collect())                    # вернуть все эллементы\n",
        "print(rdd.first())                      # вернуть первый элемент\n",
        "print(rdd.take(5))                      # вернуть первые N элементов\n",
        "print(rdd.top(3))                       # Вернуть первые N элементов упорядоченные по убыванию\n",
        "print(rdd.takeOrdered(7, lambda x: -x)) # Вернуть N эллементов, отсортированных согласно какой то \"функции\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
            "0\n",
            "[0, 1, 2, 3, 4]\n",
            "[13, 12, 11]\n",
            "[13, 12, 11, 10, 9, 8, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3zrE7Pxf2Z0",
        "colab_type": "text"
      },
      "source": [
        "# Упражнение: Решето Эратосфена.\n",
        "\n",
        "Напишите алгоритм просеивания простых чисел оперирую pyspark\n",
        "\n",
        "Подсказка: все не так то просто, последовательные фильтры надо явно заставлять выполнять"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swnkFT3Ef2Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "013f339b-aef4-400d-f010-52eff71a9626"
      },
      "source": [
        "n = 1000\n",
        "primes = sc.parallelize(range(2, n), numSlices=4)\n",
        "true_primes = []\n",
        "# перебираем делители\n",
        "for div in range(int(n**0.5)):\n",
        "  # берем первое число в массиве primes\n",
        "  prime = primes.first()\n",
        "  true_primes.append(prime)\n",
        "  # фильтруем: все, что разделилось на prime - убираем\n",
        "  primes = primes.filter(lambda x: x%prime)\n",
        "  # primes - это новый датасет из того, что осталось после фильтрации\n",
        "  # просто primes - это ссылка на объект, для материализации нужно вызвать primes.collect()\n",
        "  primes = sc.parallelize(primes.collect(), numSlices=4)\n",
        "\n",
        "\n",
        "true_primes.extend(primes.collect())\n",
        "print(true_primes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, 547, 557, 563, 569, 571, 577, 587, 593, 599, 601, 607, 613, 617, 619, 631, 641, 643, 647, 653, 659, 661, 673, 677, 683, 691, 701, 709, 719, 727, 733, 739, 743, 751, 757, 761, 769, 773, 787, 797, 809, 811, 821, 823, 827, 829, 839, 853, 857, 859, 863, 877, 881, 883, 887, 907, 911, 919, 929, 937, 941, 947, 953, 967, 971, 977, 983, 991, 997]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqntOMyCf2Z1",
        "colab_type": "text"
      },
      "source": [
        "### RDD может использовать кеши\n",
        "Spark позволяет пользователю контролировать, какие данные и как кэшируются. Правильное кэширование RDD может быть чрезвычайно полезным! Всякий раз, когда у вас есть RDD, который будет использоваться повторно несколько раз, вам следует рассмотреть возможность его кэширования.\n",
        "\n",
        " часть кеширования остается на узлах, в мастере хранятся только агреггированные результаты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjXa2VV5f2Z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d8beb592-c902-4cd4-d5a2-a68aad3cc327"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "NUM_SAMPLES = int(1e6)\n",
        "rddBig = sc.parallelize(np.random.random(NUM_SAMPLES))\n",
        "\n",
        "# нет кэширования: будет пересчитываться каждый раз, когда мы проходим цикл\n",
        "rddBigTrans = rddBig.map(lambda x: (x ** 2 - 0.1) ** 0.5)\n",
        "print(rddBigTrans.getStorageLevel())\n",
        "for threshold in (0.2, 0.4, 0.6, 0.8):\n",
        "    %timeit -n 1 -r 1 rddBigTrans.filter(lambda x: x >= threshold).count()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serialized 1x Replicated\n",
            "1 loop, best of 1: 2.29 s per loop\n",
            "1 loop, best of 1: 2.26 s per loop\n",
            "1 loop, best of 1: 2.24 s per loop\n",
            "1 loop, best of 1: 2.17 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK-xMnRHf2Z3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e24d8232-f745-4692-f7c5-59150e4da21e"
      },
      "source": [
        "# мы кешируем этот промежуточный результат, потому что он будет неоднократно вызываться\n",
        "rddBigTrans_c = rddBig.map(lambda x: (x ** 2 - 0.1) ** 0.5).cache()\n",
        "print(rddBigTrans_c.getStorageLevel())\n",
        "for threshold in (0.2, 0.4, 0.6, 0.8):\n",
        "    %timeit -n 1 -r 1 rddBigTrans_c.filter(lambda x: x >= threshold).count()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory Serialized 1x Replicated\n",
            "1 loop, best of 1: 4.97 s per loop\n",
            "1 loop, best of 1: 771 ms per loop\n",
            "1 loop, best of 1: 779 ms per loop\n",
            "1 loop, best of 1: 823 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhziz9KDf2Z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad22d30c-f627-4626-8e60-78ede1fe74fb"
      },
      "source": [
        "# используем unpersist для удаления из кэша\n",
        "# Serialized 1x Replicated - данные сериализованные с 1 репликой\n",
        "print(rddBigTrans_c.unpersist().getStorageLevel())\n",
        "# для еще более детального управления кэшированием используйте функцию «persist» \n",
        "from pyspark import storagelevel\n",
        "# явно задаем, где хранить данные \n",
        "print(rddBigTrans.persist(storagelevel.StorageLevel.MEMORY_AND_DISK).getStorageLevel())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serialized 1x Replicated\n",
            "Disk Memory Serialized 1x Replicated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiByBqUlf2Z7",
        "colab_type": "text"
      },
      "source": [
        "### Spark: key-value хранилище\n",
        "Так называемые PairRDD - это RDD, в которых хранятся пары ключ-значение. В Spark используется множество специальных операций, таких как объединение по ключу, группирование по ключу и т. д."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_RkHTFIf2Z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "eb13fbc5-b1c1-4ce6-a794-75ed075388f6"
      },
      "source": [
        "# PairRDD автоматически создаются всякий раз, когда мы представляем список кортежей ключ-значение\n",
        "# Здесь мы трансформируем rddA и создаем ключ на основе четных / нечетных флагов.\n",
        "rddP1 = rdd.map(lambda x: (x % 2 == 0, x))\n",
        "rddP1.collect()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(True, 0),\n",
              " (False, 1),\n",
              " (True, 2),\n",
              " (False, 3),\n",
              " (True, 4),\n",
              " (False, 5),\n",
              " (True, 6),\n",
              " (False, 7),\n",
              " (True, 8),\n",
              " (False, 9),\n",
              " (True, 10),\n",
              " (False, 11),\n",
              " (True, 12),\n",
              " (False, 13)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXeg7efGf2Z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "528e12f0-e83b-4081-e473-af26df911c97"
      },
      "source": [
        "# Более понятный вариант для этого:\n",
        "rddP1 = rdd.keyBy(lambda x: x % 2 == 0)\n",
        "rddP1.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(True, 0),\n",
              " (False, 1),\n",
              " (True, 2),\n",
              " (False, 3),\n",
              " (True, 4),\n",
              " (False, 5),\n",
              " (True, 6),\n",
              " (False, 7),\n",
              " (True, 8),\n",
              " (False, 9),\n",
              " (True, 10),\n",
              " (False, 11),\n",
              " (True, 12),\n",
              " (False, 13)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGMBoIbzf2Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b96139cc-a074-41fd-a34f-611d13676609"
      },
      "source": [
        "# Другой способ создать PairRDD - это заархивировать два RDD (предполагается, что RDD одинаковой длины)\n",
        "print(\"Zipped: {}\".format(rdd.zip(rdd).collect()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zipped: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdnEPaXGf2Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63b04bdd-97a7-4d05-9c10-9f49fbffa5da"
      },
      "source": [
        "# Доступ к ключам и значениям\n",
        "print(\"Keys: {}\".format(rddP1.keys().collect()))\n",
        "print(\"Values: {}\".format(rddP1.values().collect()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys: [True, False, True, False, True, False, True, False, True, False, True, False, True, False]\n",
            "Values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPIdC9jof2aA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2567107b-4eda-4e3c-f963-6c75467ca3c6"
      },
      "source": [
        "# Другой вариант обращения к ключам-значением - через кортеж; x[0] - key, x[1] - value\n",
        "print(rddP1.map(lambda x: (x[0], x[1] ** 2)).collect())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(True, 0), (False, 1), (True, 4), (False, 9), (True, 16), (False, 25), (True, 36), (False, 49), (True, 64), (False, 81), (True, 100), (False, 121), (True, 144), (False, 169)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdg6fUkJf2aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "20c3ac5c-939b-497b-8e47-77693ca3dbea"
      },
      "source": [
        "# Лучше: mapValues / flatMapValues, который работает только со значениями и сохраняет ключи на месте\n",
        "print(rddP1.mapValues(lambda x: x ** 2).collect())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(True, 0), (False, 1), (True, 4), (False, 9), (True, 16), (False, 25), (True, 36), (False, 49), (True, 64), (False, 81), (True, 100), (False, 121), (True, 144), (False, 169)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqrS-ccAf2aC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5668e575-d84a-4403-e3ef-f16b0e7bd102"
      },
      "source": [
        "# Мы также можем вернуться от PairRDD к обычному RDD, просто опустив ключ\n",
        "print(rddP1.map(lambda x: x[1] ** 2).collect())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxOBL8E6f2aD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eba2abd6-f195-4073-c95e-ca0f0488d93d"
      },
      "source": [
        "# Возможны различные агрегации по ключу, такие как reduceByKey, combineByKey и foldByKey\n",
        "# пример с reduceByKey:\n",
        "print(\"Sum per key: {}\".format(rddP1.reduceByKey(lambda x, y: x + y).collect()))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sum per key: [(False, 49), (True, 42)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwxIgrRzf2aF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdd84f9c-1e6c-4bab-e97a-5e4863464cd6"
      },
      "source": [
        "# Кроме того, некоторые общие операции доступны в форме «ByKey», например:\n",
        "rddP1.sortByKey()\n",
        "rddP1.countByKey()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {False: 7, True: 7})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VVwN2o7f2aG",
        "colab_type": "text"
      },
      "source": [
        "# Группировка и соединение по ключу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9ORSlJAf2aG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "84c28f65-9c57-4946-8aa9-78467a681ed2"
      },
      "source": [
        "# Существуют различные возможные способы объединения двух RDD по ключу:\n",
        "rddP2 = sc.parallelize(range(0, 28, 2)).map(lambda x: (x % 2 == 0, x))\n",
        "rddP2.collect()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(True, 0),\n",
              " (True, 2),\n",
              " (True, 4),\n",
              " (True, 6),\n",
              " (True, 8),\n",
              " (True, 10),\n",
              " (True, 12),\n",
              " (True, 14),\n",
              " (True, 16),\n",
              " (True, 18),\n",
              " (True, 20),\n",
              " (True, 22),\n",
              " (True, 24),\n",
              " (True, 26)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9b4ygquf2aI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "bbed5b54-2980-4b3c-a2a4-731a37429f59"
      },
      "source": [
        "# inner join / cross join в случае наложения ключей\n",
        "print(\"Join: {}\".format(rddP1.join(rddP2).collect()))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Join: [(True, (0, 0)), (True, (0, 2)), (True, (0, 4)), (True, (0, 6)), (True, (0, 8)), (True, (0, 10)), (True, (0, 12)), (True, (0, 14)), (True, (0, 16)), (True, (0, 18)), (True, (0, 20)), (True, (0, 22)), (True, (0, 24)), (True, (0, 26)), (True, (2, 0)), (True, (2, 2)), (True, (2, 4)), (True, (2, 6)), (True, (2, 8)), (True, (2, 10)), (True, (2, 12)), (True, (2, 14)), (True, (2, 16)), (True, (2, 18)), (True, (2, 20)), (True, (2, 22)), (True, (2, 24)), (True, (2, 26)), (True, (4, 0)), (True, (4, 2)), (True, (4, 4)), (True, (4, 6)), (True, (4, 8)), (True, (4, 10)), (True, (4, 12)), (True, (4, 14)), (True, (4, 16)), (True, (4, 18)), (True, (4, 20)), (True, (4, 22)), (True, (4, 24)), (True, (4, 26)), (True, (6, 0)), (True, (6, 2)), (True, (6, 4)), (True, (6, 6)), (True, (6, 8)), (True, (6, 10)), (True, (6, 12)), (True, (6, 14)), (True, (6, 16)), (True, (6, 18)), (True, (6, 20)), (True, (6, 22)), (True, (6, 24)), (True, (6, 26)), (True, (8, 0)), (True, (8, 2)), (True, (8, 4)), (True, (8, 6)), (True, (8, 8)), (True, (8, 10)), (True, (8, 12)), (True, (8, 14)), (True, (8, 16)), (True, (8, 18)), (True, (8, 20)), (True, (8, 22)), (True, (8, 24)), (True, (8, 26)), (True, (10, 0)), (True, (10, 2)), (True, (10, 4)), (True, (10, 6)), (True, (10, 8)), (True, (10, 10)), (True, (10, 12)), (True, (10, 14)), (True, (10, 16)), (True, (10, 18)), (True, (10, 20)), (True, (10, 22)), (True, (10, 24)), (True, (10, 26)), (True, (12, 0)), (True, (12, 2)), (True, (12, 4)), (True, (12, 6)), (True, (12, 8)), (True, (12, 10)), (True, (12, 12)), (True, (12, 14)), (True, (12, 16)), (True, (12, 18)), (True, (12, 20)), (True, (12, 22)), (True, (12, 24)), (True, (12, 26))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hw-ge7Rf2aJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17d0bb5d-428b-4201-964f-2a6e3e02287f"
      },
      "source": [
        "# left/right outer join\n",
        "rddP1.leftOuterJoin(rddP2)\n",
        "rddP1.rightOuterJoin(rddP2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[112] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBp0VA6Uf2aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# для всех ключей в rddP1 или rddP2 cogroup возвращает итерируемые значения\n",
        "# \n",
        "print(\"Cogroup: {}\".format(rddP1.cogroup(rddP2).collect()))\n",
        "# Группируем вместе более двух RDD по ключу можно с помощью groupWith\n",
        "rddP1.groupWith(rddP2, rddP2)\n",
        "\n",
        "# с groupByKey мы создаем новый RDD, который сохраняет те же ключи на том же узле, где это возможно\n",
        "print(\"After groupByKey: {}\".format(rddP1.groupByKey().glom().collect()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ULF6pXWEhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e5d3660-100f-4b33-f12a-22d78ad68683"
      },
      "source": [
        "a = rddP1.cogroup(rddP2).collect()\n",
        "list(a[0][1])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<pyspark.resultiterable.ResultIterable at 0x7effbc763f60>,\n",
              " <pyspark.resultiterable.ResultIterable at 0x7effbc769048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfSBne5yf2aL",
        "colab_type": "text"
      },
      "source": [
        "### Spark: работа напряму с созданием фреймов RDD из текстовых файлов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQW9rFHFf2aL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "42bb95e6-b504-4a59-e965-04c4ea5dfd1d"
      },
      "source": [
        "# TODO: Вариант для colab, локально можно поискать другие удобные файлы\n",
        "from pyspark import SparkFiles\n",
        "sc.addFile(os.path.join('/content/sample_data', 'README.md'))\n",
        "rddT = sc.textFile(SparkFiles.get('README.md'))\n",
        "# берем первые 5 строчек\n",
        "print(rddT.take(5))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This directory includes a few sample datasets to get you started.', '', '*   `california_housing_data*.csv` is California housing data from the 1990 US', '    Census; more information is available at:', '    https://developers.google.com/machine-learning/crash-course/california-housing-data-description']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juPAMpfSf2aM",
        "colab_type": "text"
      },
      "source": [
        "### RDDs простые статистические аггрегаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0t_Cluf2aN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a216f902-8ea4-45dd-a3d7-a32e6d0acd18"
      },
      "source": [
        "# reducers\n",
        "print(rdd.stats())\n",
        "print(rdd.count())\n",
        "print(rdd.sum())\n",
        "print(rdd.mean())\n",
        "print(rdd.stdev(), rdd.sampleStdev())\n",
        "print(rdd.variance(), rdd.sampleVariance())\n",
        "print(rdd.min(), rdd.max())\n",
        "print(rdd.histogram(5))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(count: 14, mean: 6.5, stdev: 4.031128874149275, max: 13.0, min: 0.0)\n",
            "14\n",
            "91\n",
            "6.5\n",
            "4.031128874149275 4.183300132670378\n",
            "16.25 17.5\n",
            "0 13\n",
            "([0.0, 2.6, 5.2, 7.800000000000001, 10.4, 13], [3, 3, 2, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn9qsfc_f2aO",
        "colab_type": "text"
      },
      "source": [
        "### RDDs преобразования множеств"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ei-AD3Gf2aO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "21c51577-1620-410f-cc0e-8dd1959552de"
      },
      "source": [
        "rddB = sc.parallelize(range(0, 26, 2))\n",
        "print(rdd.union(rddB).collect()) # or: rdd + rddB\n",
        "# не сортированы\n",
        "print(rdd.union(rddB).distinct().collect())\n",
        "print(rdd.intersection(rddB).collect())\n",
        "print(rdd.subtract(rddB).collect())\n",
        "# декартово произведение: каждому элементу одного множества ставим элемент из второго множества\n",
        "print(rdd.cartesian(rddB).collect())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
            "[0, 5, 10, 20, 1, 6, 11, 16, 2, 7, 12, 22, 3, 8, 13, 18, 4, 9, 14, 24]\n",
            "[0, 10, 6, 2, 12, 8, 4]\n",
            "[5, 1, 11, 7, 3, 13, 9]\n",
            "[(0, 0), (0, 2), (0, 4), (0, 6), (0, 8), (0, 10), (0, 12), (0, 14), (0, 16), (0, 18), (0, 20), (0, 22), (0, 24), (1, 0), (2, 0), (1, 2), (1, 4), (2, 2), (2, 4), (1, 6), (1, 8), (1, 10), (1, 12), (2, 6), (2, 8), (2, 10), (2, 12), (1, 14), (1, 16), (1, 18), (1, 20), (1, 22), (1, 24), (2, 14), (2, 16), (2, 18), (2, 20), (2, 22), (2, 24), (3, 0), (3, 2), (3, 4), (3, 6), (3, 8), (3, 10), (3, 12), (3, 14), (3, 16), (3, 18), (3, 20), (3, 22), (3, 24), (4, 0), (5, 0), (4, 2), (4, 4), (5, 2), (5, 4), (4, 6), (4, 8), (4, 10), (4, 12), (5, 6), (5, 8), (5, 10), (5, 12), (4, 14), (4, 16), (4, 18), (4, 20), (4, 22), (4, 24), (5, 14), (5, 16), (5, 18), (5, 20), (5, 22), (5, 24), (6, 0), (6, 2), (6, 4), (6, 6), (6, 8), (6, 10), (6, 12), (6, 14), (6, 16), (6, 18), (6, 20), (6, 22), (6, 24), (7, 0), (7, 2), (7, 4), (7, 6), (7, 8), (7, 10), (7, 12), (7, 14), (7, 16), (7, 18), (7, 20), (7, 22), (7, 24), (8, 0), (9, 0), (8, 2), (8, 4), (9, 2), (9, 4), (8, 6), (8, 8), (8, 10), (8, 12), (9, 6), (9, 8), (9, 10), (9, 12), (8, 14), (8, 16), (8, 18), (8, 20), (8, 22), (8, 24), (9, 14), (9, 16), (9, 18), (9, 20), (9, 22), (9, 24), (10, 0), (10, 2), (10, 4), (10, 6), (10, 8), (10, 10), (10, 12), (10, 14), (10, 16), (10, 18), (10, 20), (10, 22), (10, 24), (11, 0), (12, 0), (11, 2), (11, 4), (12, 2), (12, 4), (11, 6), (11, 8), (11, 10), (11, 12), (12, 6), (12, 8), (12, 10), (12, 12), (11, 14), (11, 16), (11, 18), (11, 20), (11, 22), (11, 24), (12, 14), (12, 16), (12, 18), (12, 20), (12, 22), (12, 24), (13, 0), (13, 2), (13, 4), (13, 6), (13, 8), (13, 10), (13, 12), (13, 14), (13, 16), (13, 18), (13, 20), (13, 22), (13, 24)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BMlKyj8f2aP",
        "colab_type": "text"
      },
      "source": [
        "### Spark поддержка общих переменных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLL8_BDf2aP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8394d6df-de20-454b-95f1-133706079c3f"
      },
      "source": [
        "# Общая переменная копируется на каждую машину только один раз, эффективным образом.\n",
        "# Это очень удобно, когда каждый узел использует данные в нем, и особенно, если данные\n",
        "# большие и в противном случае будут отправлены по сети несколько раз.\n",
        "# такая переменная отправляется на каждый узел, таким образом данные не гоняются каждый раз из мастера в узлы\n",
        "broadcastVar = sc.broadcast({'CA': 'California', 'NL': 'Netherlands'})\n",
        "print(broadcastVar.value)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-015b332c2067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# большие и в противном случае будут отправлены по сети несколько раз.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# такая переменная отправляется на каждый узел, таким образом данные не гоняются каждый раз из мастера в узлы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbroadcastVar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'CA'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'California'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NL'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Netherlands'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcastVar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYaWhZgYf2aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Аккумулятор\" является общей переменной, которая живет на главном узле,\n",
        "# который каждая операция может просматривать.\n",
        "accu = sc.accumulator(0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7X4GJxbf2aS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b026dcb-b20b-4d84-ba48-c76d266c6340"
      },
      "source": [
        "# 'foreach' просто применяет функцию к каждому элементу RDD, ничего не возвращая\n",
        "rdd.foreach(lambda x: accu.add(x))\n",
        "print(accu.value)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg8iIZ8vf2aT",
        "colab_type": "text"
      },
      "source": [
        "Популярные баги:\n",
        "--------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6tPRN_vf2aT",
        "colab_type": "text"
      },
      "source": [
        "### Не кэшировать промежуточные результаты, которые  используются позже\n",
        "\n",
        "Кешировать необходимо маленькие объемы данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCHMbldvf2aT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Not so great:\")\n",
        "rddBigTrans = rddBig.map(lambda x: (x ** 2 - 0.1) ** 0.5)\n",
        "for threshold in (0.2, 0.4, 0.6, 0.8):\n",
        "    %timeit -n 1 -r 1 rddBigTrans.filter(lambda x: x >= threshold).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Kpya0Of2aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Better:\")\n",
        "rddBigTrans_c = rddBig.map(lambda x: (x ** 2 - 0.1) ** 0.5).cache()\n",
        "for threshold in (0.2, 0.4, 0.6, 0.8):\n",
        "    %timeit -n 1 -r 1 rddBigTrans_c.filter(lambda x: x >= threshold).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYWhuWZHf2aV",
        "colab_type": "text"
      },
      "source": [
        "### Не учитывать, когда и как данные передаются через кластер\n",
        "Имейте в виду, что Spark является распределенной вычислительной средой и что следует избегать передачи данных по сети внутри кластера (пропускная способность сети в ~100 раз дороже пропускной способности памяти).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLf0HDM2f2aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# groupByKey запускает случайное воспроизведение, поэтому по сети копируется много данных\n",
        "sumPerKey = rddP1.groupByKey().mapValues(lambda x: sum(x)).collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgIOQR9uf2aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Лучше: reduceByKey уменьшает ту передачу локально перед \"перетасовкой\"\n",
        "sumPerKey = rddP1.reduceByKey(lambda x, y: x + y).collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLjXRZ0-f2aX",
        "colab_type": "text"
      },
      "source": [
        "### Не работать с соответствующим количеством разделов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8BHJ6Tdpf2aY",
        "colab_type": "text"
      },
      "source": [
        "Недостаточное количество разделов (партиций)) приводит к плохому параллелизму в кластере.\n",
        "\n",
        "Это также оказывает нагрузку на память для определенных операций.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmvEFifMf2aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# С другой стороны, предположим, что RDD распределен по 1000 разделам,\n",
        "# но мы работаем только над небольшим подмножеством данных в RDD, например:\n",
        "rddF = rdd.filter(lambda x: x < 0.1).map(lambda x: x ** 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGXyzEdDf2aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Затем мы эффективно создаем много пустых задач и используем объединение или перераспределение.\n",
        "# было бы полезно создать RDD с меньшим количеством разделов\n",
        "rddF = rdd.filter(lambda x: x < 3).coalesce(10).map(lambda x: x ** 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RqFKmdcf2aa",
        "colab_type": "text"
      },
      "source": [
        "### Используя преобразование с высокими накладными расходами на элемент, лучше использовать mapPartitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcU0dd3af2aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Например, просто подключение к базе и отключени от нее уже требует расходов\n",
        "def db_operation(x):\n",
        "    # тут мы подключилис\n",
        "    # Поделали что-то с элементом\n",
        "    # завершаем действие, отключаемся от базы\n",
        "    pass\n",
        "\n",
        "# Особенно, если вы повторите это для каждого элемента:\n",
        "rdd.map(db_operation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjWcl31mf2ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Лучше: делайте это на уровне раздела, а не на уровне элемента.\n",
        "def vectorized_db_operation(x):\n",
        "    # тут мы подключились\n",
        "    # Поделали что-то с элементом\n",
        "    # завершаем действие, отключаемся от базы\n",
        "    pass\n",
        "\n",
        "# в таком случае мы будем обрабатывать даныне целиком пачками, они все будут вычитывать в память за раз\n",
        "result = rdd.mapPartitions(vectorized_db_operation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RschRzbZf2ac",
        "colab_type": "text"
      },
      "source": [
        "### Отправка большого количества данных вместе с вызовом функции для каждого элемента"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcMiCMMf2ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigData = np.random.random(int(1e6)) #наши \"большие данные\", мы ж все же на одной машинке работаем\n",
        "\n",
        "def myFunc(x):\n",
        "    return x * np.random.choice(bigData)\n",
        "\n",
        "# и тогда наш массив будет отправляться в каждую партицию, то есть просто гоняться по сети в холостую\n",
        "rdd.map(myFunc)\n",
        "\n",
        "# Лучше: сделать большие данные доступными только для чтения, чтобы они эффективно копировались по сети\n",
        "bigDataBC = sc.broadcast(bigData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oipcBWi6f2ae",
        "colab_type": "text"
      },
      "source": [
        "В боевых задачах\n",
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h0cAcl5f2ae",
        "colab_type": "text"
      },
      "source": [
        "### Поучим что-нибудь скайлерном"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXjCyBrxf2ae",
        "colab_type": "text"
      },
      "source": [
        "Рассмотрим полусинтетический пример. Создадим какую нибудь выборку данных, из которых мы захотим решить задачу регересси.\n",
        "\n",
        "Вот только решение ее - будем делать распределенно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujyIFJ86f2ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn import pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "N = 10000   # number of data points\n",
        "D = 100     # number of dimensions\n",
        "\n",
        "X, y = make_regression(\n",
        "    n_samples=N,\n",
        "    n_features=D,\n",
        "    n_informative=int(D*0.1),\n",
        "    n_targets=1,\n",
        "    bias=-6.,\n",
        "    noise=50.,\n",
        "    random_state=42\n",
        ")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YViwiQ05f2af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# раскидаем данные случаным образом по партициям\n",
        "samples = sc.parallelize(ShuffleSplit(y_train.size, n_iter=8))\n",
        "reg_model = pipeline.Pipeline([(\"scaler\", StandardScaler()), (\"ridge\", Ridge())])\n",
        "# это кусочек обработки данных для обучения - перегоним переменные в нормальное распределение нормировкой,\n",
        "# и потом будем запусать на них решение задачи гребневой регрессии\n",
        "\n",
        "# обучим модель на каждой пачке и примеyим к выборке\n",
        "mean_rsq = samples.map(\n",
        "    lambda (index, _): reg_model.fit(X[index], y[index]).score(X_test, y_test)\n",
        ").mean()\n",
        "print(mean_rsq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhJ9AtOwf2ag",
        "colab_type": "text"
      },
      "source": [
        "получили такой самопальный вариант нескольких моделей, которые как-то голосуют за данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o10VDeLcf2ah",
        "colab_type": "text"
      },
      "source": [
        "# Упражнение: \"не боевая\" работа \"с боевыми\" данными"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivF9x4ybf2ah",
        "colab_type": "text"
      },
      "source": [
        "Нам потребуется датасет с ценами на жилье https://www.kaggle.com/camnugent/california-housing-prices\n",
        "попробуем пообрабатывать его не привычным пандасом, а с использованием спарка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ3BP9VNf2ah",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1\n",
        "\n",
        "считаем датасет и приведем его в человеческий вид"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AacLNgayf2ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "975a31ef-e7b5-4e81-d12c-9c7788fc3f35"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# SparkSession позволяет работать с таблицей с помощью полуSQL запросов\n",
        "spark = SparkSession(sc)\n",
        "# поможет нам собрать из строчек более привычный пандасовский вариант\n",
        "# здесь нам лучше избавиться пока от заголовка в файле,\n",
        "# зато сделать данные более удобными назначива постолбцовое хранение\n",
        "rdd = sc.textFile('/content/sample_data/california_housing_train.csv')\n",
        "# названия колонок\n",
        "print(rdd.map(lambda x: x.split(',')).filter(lambda x: x[0][0] == '\"').collect())\n",
        "#  Row - преобразование, которое будет возвращать нам строку а-ля словарь\n",
        "df = rdd.map(lambda x: x.split(',')).filter(lambda x: x[0][0] != '\"').map(\n",
        "    lambda row: Row(\n",
        "        longitude=row[0],\n",
        "        latitude=row[1],\n",
        "        housing_median_age=row[2],\n",
        "        total_rooms=row[3],\n",
        "        total_bedrooms=row[4],\n",
        "        population=row[5],\n",
        "        households=row[6],\n",
        "        median_income=row[7],\n",
        "        median_house_value=row[8]\n",
        "    )\n",
        ")\n",
        "# теперь можем запускать SQL запросы к таблице\n",
        "df = df.toDF()\n",
        "df.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['\"longitude\"', '\"latitude\"', '\"housing_median_age\"', '\"total_rooms\"', '\"total_bedrooms\"', '\"population\"', '\"households\"', '\"median_income\"', '\"median_house_value\"']]\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfdEQcHbf2ai",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2 \n",
        "\n",
        "теперь проведем все колонки в типизированный вид, там же пока строки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9Ih7Thf2ai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "59d7bd72-3b42-47b4-ef43-92bf0cc13144"
      },
      "source": [
        "# пока у нас все типы - это строки, нужно поменять тип на числовой\n",
        "from pyspark.sql.types import *\n",
        "col = list(map(lambda x: x.replace('\"', ''), rdd.map(lambda x: x.split(',')).filter(lambda x: x[0][0] == '\"').collect()[0]))\n",
        "\n",
        "for name in col:\n",
        "  # cast преобразует данные к определенному типу\n",
        "  df = df.withColumn(name, df[name].cast(FloatType()))\n",
        "  \n",
        "# структура таблицы\n",
        "df.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: float (nullable = true)\n",
            " |-- latitude: float (nullable = true)\n",
            " |-- housing_median_age: float (nullable = true)\n",
            " |-- total_rooms: float (nullable = true)\n",
            " |-- total_bedrooms: float (nullable = true)\n",
            " |-- population: float (nullable = true)\n",
            " |-- households: float (nullable = true)\n",
            " |-- median_income: float (nullable = true)\n",
            " |-- median_house_value: float (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_LDJZ9Ff2aj",
        "colab_type": "text"
      },
      "source": [
        "# Задание 3\n",
        "\n",
        "Добавим новых признаков:\n",
        "    * комнат на домовладельцев\n",
        "    * жителей на домовладение\n",
        "    * доля спальных комнат относительно всех"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V9M91Hqf2ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "22a2fc76-1509-4dc4-b31e-652a01318ca2"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "df = df.withColumn('RoomsPerHouseHolder', col('total_rooms')/col('households'))\n",
        "df.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+-------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|RoomsPerHouseHolder|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+-------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0| 11.889830508474576|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|  16.52267818574514|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|  6.153846153846154|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0| 6.6415929203539825|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|  5.549618320610687|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|  5.803347280334728|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|  4.592417061611374|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|  5.139240506329114|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|  4.535037878787879|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|  5.523985239852398|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|  4.540048543689321|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|  4.549199084668192|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|  6.118483412322274|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0| 5.1732776617954075|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|  4.826666666666667|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0| 6.3740648379052365|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|          6.5546875|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0| 1.6296296296296295|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|             4.3375|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|  6.466666666666667|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9YrLEyuf2al",
        "colab_type": "text"
      },
      "source": [
        "# Стахостический градиентный спуск своими руками, как бонус"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L745fyL7f2al",
        "colab_type": "text"
      },
      "source": [
        "### Stochastic gradient descent using scikit-learn (from: https://gist.github.com/MLnick/4707012)\n",
        "Each partition is a mini-batch for the SGD, uses average weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em0NUNb7f2al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model as lm\n",
        "from sklearn.base import copy\n",
        "\n",
        "N = 10000   # Number of data points\n",
        "D = 10      # Numer of dimensions\n",
        "ITERATIONS = 5\n",
        "np.random.seed(seed=42)\n",
        "\n",
        "def generate_data(N):\n",
        "    return [[[1] if np.random.rand() < 0.5 else [0], np.random.randn(D)]\n",
        "            for _ in range(N)]\n",
        "\n",
        "def train(iterator, sgd):\n",
        "    for x in iterator:\n",
        "        sgd.partial_fit(x[1], x[0], classes=np.array([0, 1]))\n",
        "    yield sgd\n",
        "\n",
        "def merge(left, right):\n",
        "    new = copy.deepcopy(left)\n",
        "    new.coef_ += right.coef_\n",
        "    new.intercept_ += right.intercept_\n",
        "    return new\n",
        "\n",
        "def avg_model(sgd, slices):\n",
        "    sgd.coef_ /= slices\n",
        "    sgd.intercept_ /= slices\n",
        "    return sgd\n",
        "\n",
        "slices = 4\n",
        "data = generate_data(N)\n",
        "print(len(data))\n",
        "\n",
        "# init stochastic gradient descent\n",
        "sgd = lm.SGDClassifier(loss='log')\n",
        "# training\n",
        "for ii in range(ITERATIONS):\n",
        "    sgd = sc.parallelize(data, numSlices=slices) \\\n",
        "            .mapPartitions(lambda x: train(x, sgd)) \\\n",
        "            .reduce(lambda x, y: merge(x, y))\n",
        "    # averaging weight vector => iterative parameter mixtures\n",
        "    sgd = avg_model(sgd, slices)\n",
        "    print(\"Iteration %d:\" % (ii + 1))\n",
        "    print(\"Model: \")\n",
        "    print(sgd.coef_)\n",
        "    print(sgd.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FiM9NEf2am",
        "colab_type": "text"
      },
      "source": [
        "The Spark universe\n",
        "------------------\n",
        "\n",
        "Other interesting tools for Spark:\n",
        "\n",
        "- Spark SQL: http://spark.apache.org/docs/latest/sql-programming-guide.html\n",
        "- MLlib, Spark's machine learning library: http://spark.apache.org/docs/latest/mllib-guide.html\n",
        "- Spark Streaming, for streaming data applications: http://spark.apache.org/docs/latest/streaming-programming-guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MpAMYFtf2am",
        "colab_type": "text"
      },
      "source": [
        "More information\n",
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa94AXtZf2an",
        "colab_type": "text"
      },
      "source": [
        "### Documentation\n",
        "\n",
        "Spark documentation: https://spark.apache.org/docs/latest/index.html\n",
        "\n",
        "Spark programming guide: http://spark.apache.org/docs/latest/programming-guide.html\n",
        "\n",
        "PySpark documentation: https://spark.apache.org/docs/latest/api/python/index.html\n",
        "\n",
        "### Books\n",
        "\n",
        "Learning Spark: http://shop.oreilly.com/product/0636920028512.do\n",
        "\n",
        "(preview: https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/)\n",
        "\n",
        "### Talks (recommended to watch them in this order)\n",
        "\n",
        "Parallel programming with Spark: https://www.youtube.com/watch?v=7k4yDKBYOcw\n",
        "\n",
        "Advanced Spark features: https://www.youtube.com/watch?v=w0Tisli7zn4\n",
        "\n",
        "PySpark: Python API for Spark: https://www.youtube.com/watch?v=xc7Lc8RA8wE\n",
        "\n",
        "Understanding Spark performance: https://www.youtube.com/watch?v=NXp3oJHNM7E\n",
        "\n",
        "A deeper understanding of Spark's internals: https://www.youtube.com/watch?v=dmL0N3qfSc8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vyGM9g8kf2an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}